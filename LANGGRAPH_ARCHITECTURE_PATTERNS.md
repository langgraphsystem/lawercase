# LangGraph Architecture Patterns –¥–ª—è mega_agent_pro

## üéØ –û—Å–Ω–æ–≤–Ω—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã

### 1. Supervisor Pattern
**–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –¶–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∏ –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è –∑–∞–¥–∞—á –º–µ–∂–¥—É –∞–≥–µ–Ω—Ç–∞–º–∏

```python
from langgraph.graph import StateGraph, START, END
from langgraph.prebuilt import create_react_agent
from typing import Literal

class SupervisorState(TypedDict):
    task: str
    selected_agents: List[str]
    agent_results: Dict[str, Any]
    final_result: Any
    routing_reasoning: str

def create_supervisor_workflow():
    """–°–æ–∑–¥–∞–Ω–∏–µ supervisor workflow —Å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–π –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–µ–π"""

    workflow = StateGraph(SupervisorState)

    # –£–∑–µ–ª –∞–Ω–∞–ª–∏–∑–∞ –∑–∞–¥–∞—á–∏
    workflow.add_node("analyze_task", analyze_task_node)

    # –£–∑–µ–ª –≤—ã–±–æ—Ä–∞ –∞–≥–µ–Ω—Ç–æ–≤
    workflow.add_node("select_agents", select_agents_node)

    # –£–∑–ª—ã —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤
    workflow.add_node("case_agent", case_agent_node)
    workflow.add_node("writer_agent", writer_agent_node)
    workflow.add_node("validator_agent", validator_agent_node)
    workflow.add_node("rag_agent", rag_agent_node)

    # –£–∑–µ–ª —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    workflow.add_node("synthesize_results", synthesize_results_node)

    # –ú–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è
    workflow.add_edge(START, "analyze_task")
    workflow.add_edge("analyze_task", "select_agents")

    # –£—Å–ª–æ–≤–Ω–∞—è –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è –∫ –∞–≥–µ–Ω—Ç–∞–º
    workflow.add_conditional_edges(
        "select_agents",
        route_to_agents,
        {
            "case_processing": "case_agent",
            "document_generation": "writer_agent",
            "validation": "validator_agent",
            "information_retrieval": "rag_agent",
            "parallel_processing": "parallel_execution"
        }
    )

    # –í–æ–∑–≤—Ä–∞—Ç –∫ —Å–∏–Ω—Ç–µ–∑—É
    workflow.add_edge("case_agent", "synthesize_results")
    workflow.add_edge("writer_agent", "synthesize_results")
    workflow.add_edge("validator_agent", "synthesize_results")
    workflow.add_edge("rag_agent", "synthesize_results")

    workflow.add_edge("synthesize_results", END)

    return workflow.compile()

async def analyze_task_node(state: SupervisorState) -> SupervisorState:
    """–ê–Ω–∞–ª–∏–∑ –∑–∞–¥–∞—á–∏ —Å –ø–æ–º–æ—â—å—é LLM"""

    analysis_prompt = f"""
    –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â—É—é –∑–∞–¥–∞—á—É –∏ –æ–ø—Ä–µ–¥–µ–ª–∏ –µ—ë —Ç–∏–ø –∏ —Å–ª–æ–∂–Ω–æ—Å—Ç—å:

    –ó–∞–¥–∞—á–∞: {state['task']}

    –í–µ—Ä–Ω–∏ –∞–Ω–∞–ª–∏–∑ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON:
    {{
        "task_type": "case_creation|document_generation|validation|research|complex",
        "complexity": "simple|medium|complex",
        "required_agents": ["agent1", "agent2"],
        "estimated_time": "–≤—Ä–µ–º—è –≤ –º–∏–Ω—É—Ç–∞—Ö",
        "dependencies": ["–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å1", "–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å2"]
    }}
    """

    llm = ChatOpenAI(model="gpt-4o", temperature=0)
    response = await llm.ainvoke([HumanMessage(content=analysis_prompt)])

    analysis = json.loads(response.content)
    state['task_analysis'] = analysis

    return state
```

### 2. Fan-out/Fan-in Pattern
**–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–¥–∞—á —Å –ø–æ—Å–ª–µ–¥—É—é—â–∏–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

```python
from langgraph.graph import StateGraph, START, END
from langgraph.constants import Send

class ParallelProcessingState(TypedDict):
    query: str
    parallel_tasks: List[str]
    agent_results: Dict[str, Any]
    merged_result: Any

def create_parallel_workflow():
    """Workflow –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏"""

    workflow = StateGraph(ParallelProcessingState)

    # –£–∑–µ–ª —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –∑–∞–¥–∞—á
    workflow.add_node("split_tasks", split_tasks_node)

    # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ —É–∑–ª—ã
    workflow.add_node("rag_search", rag_search_node)
    workflow.add_node("legal_research", legal_research_node)
    workflow.add_node("case_analysis", case_analysis_node)

    # –£–∑–µ–ª –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è
    workflow.add_node("merge_results", merge_results_node)

    # Fan-out –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è
    workflow.add_conditional_edges(
        "split_tasks",
        fan_out_routing,
        ["rag_search", "legal_research", "case_analysis"]
    )

    # Fan-in - –≤—Å–µ –ø—É—Ç–∏ –≤–µ–¥—É—Ç –∫ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—é
    workflow.add_edge("rag_search", "merge_results")
    workflow.add_edge("legal_research", "merge_results")
    workflow.add_edge("case_analysis", "merge_results")

    workflow.add_edge("merge_results", END)

    return workflow.compile()

async def fan_out_routing(state: ParallelProcessingState) -> List[Send]:
    """–î–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∑–∞–¥–∞—á"""

    sends = []
    for task in state['parallel_tasks']:
        if task == "rag_search":
            sends.append(Send("rag_search", {"query": state['query'], "task_type": "rag"}))
        elif task == "legal_research":
            sends.append(Send("legal_research", {"query": state['query'], "task_type": "legal"}))
        elif task == "case_analysis":
            sends.append(Send("case_analysis", {"query": state['query'], "task_type": "case"}))

    return sends

async def merge_results_node(state: ParallelProcessingState) -> ParallelProcessingState:
    """–ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""

    # –°–±–æ—Ä –≤—Å–µ—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    all_results = state['agent_results']

    # LLM-based —Å–∏–Ω—Ç–µ–∑
    synthesis_prompt = f"""
    –û–±—ä–µ–¥–∏–Ω–∏ —Å–ª–µ–¥—É—é—â–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ç —Ä–∞–∑–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤ –≤ –µ–¥–∏–Ω—ã–π –æ—Ç–≤–µ—Ç:

    RAG —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {all_results.get('rag_search', '')}
    –Æ—Ä–∏–¥–∏—á–µ—Å–∫–æ–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ: {all_results.get('legal_research', '')}
    –ê–Ω–∞–ª–∏–∑ –¥–µ–ª–∞: {all_results.get('case_analysis', '')}

    –°–æ–∑–¥–∞–π —Å–≤—è–∑–Ω—ã–π –∏ –ø–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç, —É—á–∏—Ç—ã–≤–∞—è –≤—Å–µ –Ω–∞–π–¥–µ–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é.
    """

    llm = ChatOpenAI(model="gpt-4o")
    response = await llm.ainvoke([HumanMessage(content=synthesis_prompt)])

    state['merged_result'] = response.content
    return state
```

### 3. Self-Correction Pattern
**–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∫–æ—Ä—Ä–µ–∫—Ü–∏—è –∏ —É–ª—É—á—à–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–≥–µ–Ω—Ç–æ–≤

```python
class SelfCorrectionState(TypedDict):
    task: str
    initial_result: Any
    corrections: List[Dict]
    final_result: Any
    confidence_score: float
    correction_count: int

def create_self_correction_workflow():
    """Workflow –¥–ª—è —Å–∞–º–æ–∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ –∞–≥–µ–Ω—Ç–æ–≤"""

    workflow = StateGraph(SelfCorrectionState)

    workflow.add_node("initial_execution", initial_execution_node)
    workflow.add_node("confidence_assessment", confidence_assessment_node)
    workflow.add_node("reflection", reflection_node)
    workflow.add_node("correction", correction_node)
    workflow.add_node("finalize", finalize_node)

    workflow.add_edge(START, "initial_execution")
    workflow.add_edge("initial_execution", "confidence_assessment")

    # –£—Å–ª–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏
    workflow.add_conditional_edges(
        "confidence_assessment",
        should_correct,
        {
            "correct": "reflection",
            "finalize": "finalize"
        }
    )

    workflow.add_edge("reflection", "correction")
    workflow.add_edge("correction", "confidence_assessment")  # –¶–∏–∫–ª –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏
    workflow.add_edge("finalize", END)

    return workflow.compile()

async def confidence_assessment_node(state: SelfCorrectionState) -> SelfCorrectionState:
    """–û—Ü–µ–Ω–∫–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ"""

    assessment_prompt = f"""
    –û—Ü–µ–Ω–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ —Å–ª–µ–¥—É—é—â–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ –ø–æ —à–∫–∞–ª–µ –æ—Ç 0 –¥–æ 1:

    –ó–∞–¥–∞—á–∞: {state['task']}
    –†–µ–∑—É–ª—å—Ç–∞—Ç: {state['initial_result']}

    –ö—Ä–∏—Ç–µ—Ä–∏–∏ –æ—Ü–µ–Ω–∫–∏:
    - –ü–æ–ª–Ω–æ—Ç–∞ (–≤—Å–µ –∞—Å–ø–µ–∫—Ç—ã –∑–∞–¥–∞—á–∏ –ø–æ–∫—Ä—ã—Ç—ã)
    - –¢–æ—á–Ω–æ—Å—Ç—å (–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞)
    - –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å (–æ—Ç–≤–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –≤–æ–ø—Ä–æ—Å—É)
    - –Ø—Å–Ω–æ—Å—Ç—å (—Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–Ω—è—Ç–µ–Ω)

    –í–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ —á–∏—Å–ª–æ –æ—Ç 0 –¥–æ 1:
    """

    llm = ChatOpenAI(model="gpt-4o", temperature=0)
    response = await llm.ainvoke([HumanMessage(content=assessment_prompt)])

    try:
        confidence = float(response.content.strip())
        state['confidence_score'] = confidence
    except:
        state['confidence_score'] = 0.5

    return state

def should_correct(state: SelfCorrectionState) -> Literal["correct", "finalize"]:
    """–†–µ—à–µ–Ω–∏–µ –æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏"""

    if (state['confidence_score'] < 0.8 and
        state.get('correction_count', 0) < 3):
        return "correct"
    else:
        return "finalize"

async def reflection_node(state: SelfCorrectionState) -> SelfCorrectionState:
    """–†–µ—Ñ–ª–µ–∫—Å–∏—è –Ω–∞–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º –¥–ª—è –≤—ã—è–≤–ª–µ–Ω–∏—è –ø—Ä–æ–±–ª–µ–º"""

    reflection_prompt = f"""
    –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∏ –Ω–∞–π–¥–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è:

    –ó–∞–¥–∞—á–∞: {state['task']}
    –¢–µ–∫—É—â–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {state['initial_result']}
    –û—Ü–µ–Ω–∫–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏: {state['confidence_score']}

    –û–ø—Ä–µ–¥–µ–ª–∏:
    1. –ß—Ç–æ –∏–º–µ–Ω–Ω–æ –Ω—É–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å?
    2. –ö–∞–∫–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç?
    3. –ö–∞–∫–∏–µ –µ—Å—Ç—å –Ω–µ—Ç–æ—á–Ω–æ—Å—Ç–∏?
    4. –ö–∞–∫ –º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å –æ—Ç–≤–µ—Ç –±–æ–ª–µ–µ –ø–æ–ª–Ω—ã–º?

    –í–µ—Ä–Ω–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è.
    """

    llm = ChatOpenAI(model="gpt-4o")
    response = await llm.ainvoke([HumanMessage(content=reflection_prompt)])

    if 'corrections' not in state:
        state['corrections'] = []

    state['corrections'].append({
        "iteration": len(state['corrections']) + 1,
        "reflection": response.content,
        "timestamp": datetime.utcnow().isoformat()
    })

    return state
```

### 4. Human-in-the-Loop Pattern
**–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–≥–æ –∫–æ–Ω—Ç—Ä–æ–ª—è –≤ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö —Ç–æ—á–∫–∞—Ö workflow

```python
class HITLState(TypedDict):
    task: str
    ai_recommendation: str
    human_decision: Optional[str]
    final_action: str
    requires_approval: bool

def create_hitl_workflow():
    """Workflow —Å human-in-the-loop checkpoints"""

    workflow = StateGraph(HITLState)

    workflow.add_node("ai_analysis", ai_analysis_node)
    workflow.add_node("risk_assessment", risk_assessment_node)
    workflow.add_node("human_review", human_review_node)
    workflow.add_node("execute_action", execute_action_node)

    workflow.add_edge(START, "ai_analysis")
    workflow.add_edge("ai_analysis", "risk_assessment")

    # –£—Å–ª–æ–≤–Ω–∞—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –¥–ª—è —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–≥–æ —Ä–µ—à–µ–Ω–∏—è
    workflow.add_conditional_edges(
        "risk_assessment",
        requires_human_approval,
        {
            "human_needed": "human_review",
            "auto_proceed": "execute_action"
        }
    )

    workflow.add_edge("human_review", "execute_action")
    workflow.add_edge("execute_action", END)

    # –ö–æ–º–ø–∏–ª—è—Ü–∏—è —Å interrupt points
    return workflow.compile(
        checkpointer=checkpointer,
        interrupt_before=["human_review"]
    )

async def risk_assessment_node(state: HITLState) -> HITLState:
    """–û—Ü–µ–Ω–∫–∞ —Ä–∏—Å–∫–æ–≤ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–≥–æ –≤–º–µ—à–∞—Ç–µ–ª—å—Å—Ç–≤–∞"""

    risk_prompt = f"""
    –û—Ü–µ–Ω–∏ —Ä–∏—Å–∫–∏ —Å–ª–µ–¥—É—é—â–µ–≥–æ –¥–µ–π—Å—Ç–≤–∏—è:

    –ó–∞–¥–∞—á–∞: {state['task']}
    –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è –ò–ò: {state['ai_recommendation']}

    –ö—Ä–∏—Ç–µ—Ä–∏–∏ –≤—ã—Å–æ–∫–æ–≥–æ —Ä–∏—Å–∫–∞:
    - –§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –ø–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è > $10,000
    - –Æ—Ä–∏–¥–∏—á–µ—Å–∫–∏–µ —Ä–∏—Å–∫–∏
    - –ë–µ–∑–≤–æ–∑–≤—Ä–∞—Ç–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è
    - –í–ª–∏—è–Ω–∏–µ –Ω–∞ –∫–ª–∏–µ–Ω—Ç—Å–∫–∏–µ –æ—Ç–Ω–æ—à–µ–Ω–∏—è

    –í–µ—Ä–Ω–∏ JSON:
    {{
        "risk_level": "low|medium|high",
        "risk_factors": ["—Ñ–∞–∫—Ç–æ—Ä1", "—Ñ–∞–∫—Ç–æ—Ä2"],
        "requires_approval": true/false,
        "reasoning": "–æ–±—ä—è—Å–Ω–µ–Ω–∏–µ"
    }}
    """

    llm = ChatOpenAI(model="gpt-4o", temperature=0)
    response = await llm.ainvoke([HumanMessage(content=risk_prompt)])

    risk_assessment = json.loads(response.content)
    state['requires_approval'] = risk_assessment['requires_approval']
    state['risk_assessment'] = risk_assessment

    return state

def requires_human_approval(state: HITLState) -> Literal["human_needed", "auto_proceed"]:
    """–ú–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ—Ü–µ–Ω–∫–∏ —Ä–∏—Å–∫–æ–≤"""
    return "human_needed" if state['requires_approval'] else "auto_proceed"

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Å –ø–∞—É–∑–æ–π –¥–ª—è —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–≥–æ —Ä–µ—à–µ–Ω–∏—è
async def run_with_human_approval(workflow, initial_state, thread_id):
    """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ workflow —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–≥–æ –≤–º–µ—à–∞—Ç–µ–ª—å—Å—Ç–≤–∞"""

    config = {"configurable": {"thread_id": thread_id}}

    # –ó–∞–ø—É—Å–∫ –¥–æ —Ç–æ—á–∫–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
    result = await workflow.ainvoke(initial_state, config=config)

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–≥–æ —Ä–µ—à–µ–Ω–∏—è
    if workflow.get_state(config).next == ("human_review",):
        print("–¢—Ä–µ–±—É–µ—Ç—Å—è —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–µ —Ä–µ—à–µ–Ω–∏–µ. Workflow –ø—Ä–∏–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω.")
        return "awaiting_human_input"

    return result

async def resume_with_human_decision(workflow, human_decision, thread_id):
    """–í–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ workflow –ø–æ—Å–ª–µ —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–≥–æ —Ä–µ—à–µ–Ω–∏—è"""

    config = {"configurable": {"thread_id": thread_id}}

    # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å —á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏–º —Ä–µ—à–µ–Ω–∏–µ–º
    await workflow.aupdate_state(
        config,
        {"human_decision": human_decision}
    )

    # –ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
    final_result = await workflow.ainvoke(None, config=config)
    return final_result
```

### 5. Error Recovery Pattern
**–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: Robust –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ–º

```python
class ErrorRecoveryState(TypedDict):
    task: str
    attempts: int
    last_error: Optional[str]
    fallback_strategies: List[str]
    result: Optional[Any]

def create_error_recovery_workflow():
    """Workflow —Å comprehensive error handling"""

    workflow = StateGraph(ErrorRecoveryState)

    workflow.add_node("primary_execution", primary_execution_node)
    workflow.add_node("error_analysis", error_analysis_node)
    workflow.add_node("fallback_strategy", fallback_strategy_node)
    workflow.add_node("final_fallback", final_fallback_node)

    workflow.add_edge(START, "primary_execution")

    # –£—Å–ª–æ–≤–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫
    workflow.add_conditional_edges(
        "primary_execution",
        check_execution_success,
        {
            "success": END,
            "error": "error_analysis"
        }
    )

    workflow.add_edge("error_analysis", "fallback_strategy")

    workflow.add_conditional_edges(
        "fallback_strategy",
        check_fallback_success,
        {
            "success": END,
            "retry": "primary_execution",
            "final_fallback": "final_fallback"
        }
    )

    workflow.add_edge("final_fallback", END)

    return workflow.compile()

async def primary_execution_node(state: ErrorRecoveryState) -> ErrorRecoveryState:
    """–û—Å–Ω–æ–≤–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""

    try:
        # –û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
        result = await execute_main_task(state['task'])
        state['result'] = result
        state['execution_status'] = 'success'

    except Exception as e:
        state['last_error'] = str(e)
        state['execution_status'] = 'error'
        state['attempts'] = state.get('attempts', 0) + 1

        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—à–∏–±–∫–∏
        logger.error(f"Primary execution failed: {e}", extra={
            "task": state['task'],
            "attempt": state['attempts']
        })

    return state

async def error_analysis_node(state: ErrorRecoveryState) -> ErrorRecoveryState:
    """–ê–Ω–∞–ª–∏–∑ –æ—à–∏–±–∫–∏ –¥–ª—è –≤—ã–±–æ—Ä–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è"""

    error_analysis_prompt = f"""
    –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –æ—à–∏–±–∫—É –∏ –ø—Ä–µ–¥–ª–æ–∂–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è:

    –ó–∞–¥–∞—á–∞: {state['task']}
    –û—à–∏–±–∫–∞: {state['last_error']}
    –ü–æ–ø—ã—Ç–∫–∞ –Ω–æ–º–µ—Ä: {state['attempts']}

    –í–æ–∑–º–æ–∂–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏:
    1. retry_with_backoff - –ø–æ–≤—Ç–æ—Ä–∏—Ç—å —Å –∑–∞–¥–µ—Ä–∂–∫–æ–π
    2. alternative_approach - –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥
    3. simplified_task - —É–ø—Ä–æ—Å—Ç–∏—Ç—å –∑–∞–¥–∞—á—É
    4. manual_intervention - —Ç—Ä–µ–±—É–µ—Ç—Å—è —Ä—É—á–Ω–æ–µ –≤–º–µ—à–∞—Ç–µ–ª—å—Å—Ç–≤–æ

    –í–µ—Ä–Ω–∏ JSON:
    {{
        "recommended_strategy": "strategy_name",
        "reasoning": "–æ–±—ä—è—Å–Ω–µ–Ω–∏–µ",
        "retry_delay": "—Å–µ–∫—É–Ω–¥—ã –¥–ª—è retry",
        "max_retries": "–º–∞–∫—Å–∏–º—É–º –ø–æ–ø—ã—Ç–æ–∫"
    }}
    """

    llm = ChatOpenAI(model="gpt-4o")
    response = await llm.ainvoke([HumanMessage(content=error_analysis_prompt)])

    analysis = json.loads(response.content)
    state['recovery_strategy'] = analysis

    return state

def check_execution_success(state: ErrorRecoveryState) -> Literal["success", "error"]:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è"""
    return state.get('execution_status', 'error')

def check_fallback_success(state: ErrorRecoveryState) -> Literal["success", "retry", "final_fallback"]:
    """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–ª–µ–¥—É—é—â–µ–≥–æ —à–∞–≥–∞ –ø–æ—Å–ª–µ fallback"""

    if state.get('execution_status') == 'success':
        return "success"
    elif state.get('attempts', 0) < 3:
        return "retry"
    else:
        return "final_fallback"
```

### 6. Context Enrichment Pattern
**–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –î–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ –æ–±–æ–≥–∞—â–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ö–æ–¥–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è

```python
class ContextEnrichmentState(TypedDict):
    base_context: str
    enriched_context: str
    context_sources: List[str]
    relevance_scores: Dict[str, float]

def create_context_enrichment_workflow():
    """Workflow –¥–ª—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ –æ–±–æ–≥–∞—â–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""

    workflow = StateGraph(ContextEnrichmentState)

    workflow.add_node("analyze_context_needs", analyze_context_needs_node)
    workflow.add_node("gather_related_info", gather_related_info_node)
    workflow.add_node("score_relevance", score_relevance_node)
    workflow.add_node("merge_context", merge_context_node)

    workflow.add_edge(START, "analyze_context_needs")
    workflow.add_edge("analyze_context_needs", "gather_related_info")
    workflow.add_edge("gather_related_info", "score_relevance")
    workflow.add_edge("score_relevance", "merge_context")
    workflow.add_edge("merge_context", END)

    return workflow.compile()

async def analyze_context_needs_node(state: ContextEnrichmentState) -> ContextEnrichmentState:
    """–ê–Ω–∞–ª–∏–∑ –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç–µ–π –≤ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ"""

    analysis_prompt = f"""
    –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –±–∞–∑–æ–≤—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ –æ–ø—Ä–µ–¥–µ–ª–∏, –∫–∞–∫–∞—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω—É–∂–Ω–∞:

    –ë–∞–∑–æ–≤—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç: {state['base_context']}

    –û–ø—Ä–µ–¥–µ–ª–∏:
    1. –ö–∞–∫–∏–µ –∫–ª—é—á–µ–≤—ã–µ –ø–æ–Ω—è—Ç–∏—è —Ç—Ä–µ–±—É—é—Ç —Ä–∞–∑—ä—è—Å–Ω–µ–Ω–∏—è?
    2. –ö–∞–∫–∞—è –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –º–æ–∂–µ—Ç –±—ã—Ç—å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞?
    3. –ö–∞–∫–∏–µ —Å–≤—è–∑–∞–Ω–Ω—ã–µ –¥–µ–ª–∞ –∏–ª–∏ –ø—Ä–µ—Ü–µ–¥–µ–Ω—Ç—ã —Å—Ç–æ–∏—Ç –Ω–∞–π—Ç–∏?
    4. –ö–∞–∫–∏–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –Ω—É–∂–Ω–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å?

    –í–µ—Ä–Ω–∏ —Å–ø–∏—Å–æ–∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã—Ö –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç–µ–π.
    """

    llm = ChatOpenAI(model="gpt-4o")
    response = await llm.ainvoke([HumanMessage(content=analysis_prompt)])

    state['context_needs'] = response.content
    return state
```

## üîß –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤

### –ö–æ–º–ø–æ–∑–∏—Ç–Ω—ã–π Workflow
```python
def create_mega_agent_workflow():
    """–ì–ª–∞–≤–Ω—ã–π workflow, –æ–±—ä–µ–¥–∏–Ω—è—é—â–∏–π –≤—Å–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã"""

    workflow = StateGraph(MegaAgentState)

    # Supervisor –∫–∞–∫ —Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞
    workflow.add_node("supervisor", supervisor_node)

    # –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö workflow
    workflow.add_node("self_correction_flow", self_correction_workflow)
    workflow.add_node("parallel_processing_flow", parallel_workflow)
    workflow.add_node("hitl_flow", hitl_workflow)
    workflow.add_node("error_recovery_flow", error_recovery_workflow)

    # –ú–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è –∫ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–º—É workflow
    workflow.add_conditional_edges(
        "supervisor",
        route_to_specialized_workflow,
        {
            "simple_task": "direct_execution",
            "complex_task": "parallel_processing_flow",
            "risky_task": "hitl_flow",
            "error_prone_task": "error_recovery_flow",
            "quality_critical": "self_correction_flow"
        }
    )

    return workflow.compile(
        checkpointer=PostgresSaver.from_conn_string(postgres_url),
        interrupt_before=["human_review", "critical_decision"]
    )
```

–≠—Ç–∏ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –æ–±–µ—Å–ø–µ—á–∏–≤–∞—é—Ç –Ω–∞–¥–µ–∂–Ω—É—é, –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º—É—é –∏ maintainable –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –¥–ª—è complex multi-agent —Å–∏—Å—Ç–µ–º—ã mega_agent_pro.