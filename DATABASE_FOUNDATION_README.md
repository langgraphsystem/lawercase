# üóÑÔ∏è Database Foundation - Phase 1 Implementation

## ‚úÖ –ß—Ç–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ

–ü–æ–ª–Ω–∞—è –∑–∞–º–µ–Ω–∞ in-memory —Ö—Ä–∞–Ω–∏–ª–∏—â –Ω–∞ production-ready –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—É:

### 1. **PostgreSQL** - Metadata & Audit
- ‚úÖ Semantic memory metadata (–≤–µ–∫—Ç–æ—Ä—ã —Ö—Ä–∞–Ω—è—Ç—Å—è –≤ Pinecone)
- ‚úÖ Episodic memory (audit trail)
- ‚úÖ RMT buffers (working memory)
- ‚úÖ Cases & Documents metadata
- ‚úÖ Async connection pooling
- ‚úÖ SQLAlchemy models with proper indexes

### 2. **Pinecone** - Vector Search
- ‚úÖ Serverless vector index (2048-dim)
- ‚úÖ Cosine similarity search
- ‚úÖ Metadata filtering for multi-tenancy
- ‚úÖ Automatic index creation

### 3. **Voyage AI** - Embeddings
- ‚úÖ voyage-3-large model (2048 dimensions)
- ‚úÖ Optimized for document vs query
- ‚úÖ Automatic text truncation

### 4. **Cloudflare R2** - Document Storage
- ‚úÖ S3-compatible API
- ‚úÖ PDF, images, scans storage
- ‚úÖ Presigned URLs generation
- ‚úÖ Metadata storage

---

## üìÇ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ñ–∞–π–ª–æ–≤

```
core/
‚îú‚îÄ‚îÄ storage/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py              # Public API exports
‚îÇ   ‚îú‚îÄ‚îÄ config.py                # Unified configuration
‚îÇ   ‚îú‚îÄ‚îÄ connection.py            # PostgreSQL connection manager
‚îÇ   ‚îú‚îÄ‚îÄ models.py                # SQLAlchemy models
‚îÇ   ‚îú‚îÄ‚îÄ pinecone_store.py        # Pinecone vector store
‚îÇ   ‚îú‚îÄ‚îÄ r2_storage.py            # Cloudflare R2 client
‚îÇ   ‚îú‚îÄ‚îÄ postgres_stores.py       # PostgresEpisodicStore & PostgresWorkingMemory
‚îÇ   ‚îî‚îÄ‚îÄ migrations/              # Alembic migrations
‚îú‚îÄ‚îÄ llm/
‚îÇ   ‚îî‚îÄ‚îÄ voyage_embedder.py       # Voyage AI embeddings client
‚îî‚îÄ‚îÄ memory/
    ‚îú‚îÄ‚îÄ memory_manager.py        # Updated to use new stores
    ‚îî‚îÄ‚îÄ stores/
        ‚îú‚îÄ‚îÄ semantic_store.py    # Now uses Pinecone
        ‚îú‚îÄ‚îÄ episodic_store.py    # Now uses PostgreSQL
        ‚îî‚îÄ‚îÄ working_memory.py    # Now uses PostgreSQL

requirements_storage.txt         # New dependencies
.env.example                     # Configuration template
```

---

## üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

### 1. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏

```bash
# –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –Ω–æ–≤—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
pip install -r requirements_storage.txt

# –ò–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –æ—Ç–¥–µ–ª—å–Ω–æ:
pip install sqlalchemy[asyncio] asyncpg alembic
pip install pinecone-client voyageai boto3
pip install pydantic-settings
```

### 2. –ù–∞—Å—Ç—Ä–æ–∏—Ç—å –æ–∫—Ä—É–∂–µ–Ω–∏–µ

–°–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å `.env.example` –≤ `.env` –∏ –∑–∞–ø–æ–ª–Ω–∏—Ç—å:

```bash
cp .env.example .env
nano .env  # –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –≤–∞—à –ª—é–±–∏–º—ã–π —Ä–µ–¥–∞–∫—Ç–æ—Ä
```

**–û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ:**

```env
# PostgreSQL
POSTGRES_DSN=postgresql+asyncpg://user:password@localhost:5432/megaagent  # pragma: allowlist secret

# Pinecone
PINECONE_API_KEY=pc-xxxxx
PINECONE_INDEX_NAME=mega-agent-semantic

# Voyage AI
VOYAGE_API_KEY=pa-xxxxx

# Cloudflare R2
R2_ACCOUNT_ID=your-account-id
R2_ACCESS_KEY_ID=your-access-key
R2_SECRET_ACCESS_KEY=your-secret-key
R2_ENDPOINT=https://your-account-id.r2.cloudflarestorage.com
R2_BUCKET_NAME=mega-agent-documents
```

### 3. –°–æ–∑–¥–∞—Ç—å PostgreSQL database

```bash
# –í–∞—Ä–∏–∞–Ω—Ç 1: –õ–æ–∫–∞–ª—å–Ω—ã–π PostgreSQL
createdb megaagent

# –í–∞—Ä–∏–∞–Ω—Ç 2: Docker
docker run -d \
  --name megaagent-postgres \
  -e POSTGRES_DB=megaagent \
  -e POSTGRES_USER=user \
  -e POSTGRES_PASSWORD=password \
  -p 5432:5432 \
  postgres:16-alpine

# –í–∞—Ä–∏–∞–Ω—Ç 3: Cloud (Railway, Supabase, AWS RDS)
# –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ connection string –∏–∑ –ø–∞–Ω–µ–ª–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è
```

### 4. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å database schema

```python
# create_schema.py
import asyncio
from core.storage.connection import get_db_manager

async def init_db():
    db = get_db_manager()

    # Create schema
    await db.create_schema()

    # Create all tables
    await db.create_all_tables()

    print("‚úÖ Database initialized!")

if __name__ == "__main__":
    asyncio.run(init_db())
```

```bash
python create_schema.py
```

### 5. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ

```python
# test_storage.py
import asyncio
from core.storage.connection import get_db_manager
from core.storage.pinecone_store import create_pinecone_store
from core.storage.r2_storage import create_r2_storage
from core.llm.voyage_embedder import create_voyage_embedder

async def test_connections():
    # Test PostgreSQL
    db = get_db_manager()
    pg_ok = await db.health_check()
    print(f"PostgreSQL: {'‚úÖ' if pg_ok else '‚ùå'}")

    # Test Pinecone
    pinecone = create_pinecone_store()
    pc_ok = await pinecone.health_check()
    print(f"Pinecone: {'‚úÖ' if pc_ok else '‚ùå'}")

    # Test R2
    r2 = create_r2_storage()
    r2_ok = await r2.health_check()
    print(f"R2: {'‚úÖ' if r2_ok else '‚ùå'}")

    # Test Voyage embeddings
    voyage = create_voyage_embedder()
    embedding = await voyage.aembed_query("test")
    print(f"Voyage: ‚úÖ (dimension: {len(embedding)})")

if __name__ == "__main__":
    asyncio.run(test_connections())
```

---

## üìñ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

### Semantic Memory —Å Pinecone

```python
from core.storage.pinecone_store import create_pinecone_store
from core.llm.voyage_embedder import create_voyage_embedder
from core.memory.models import MemoryRecord

# Initialize
pinecone = create_pinecone_store()
voyage = create_voyage_embedder()

# Create memory record
record = MemoryRecord(
    user_id="user_123",
    text="Important legal precedent from case XYZ",
    type="fact",
    source="case_analysis",
    tags=["legal", "precedent"]
)

# Generate embedding
embedding = await voyage.aembed_documents([record.text])

# Store in Pinecone
await pinecone.upsert([record], embedding)

# Search similar memories
query_embedding = await voyage.aembed_query("find legal precedents")
results = await pinecone.search(
    query_embedding,
    user_id="user_123",
    topk=5
)

for result in results:
    print(f"Score: {result['score']}")
    print(f"Text: {result['metadata']['text']}")
```

### Episodic Memory (Audit Trail)

```python
from core.storage.postgres_stores import PostgresEpisodicStore
from core.memory.models import AuditEvent
from uuid import uuid4

store = PostgresEpisodicStore()

# Log audit event
event = AuditEvent(
    event_id=str(uuid4()),
    user_id="user_123",
    thread_id="case_456",
    source="case_agent",
    action="create_case",
    payload={"case_id": "case_456", "title": "New Case"}
)

await store.aappend(event)

# Retrieve thread history
events = await store.aget_thread_events("case_456")
for event in events:
    print(f"{event.timestamp}: {event.action}")
```

### Document Storage –≤ R2

```python
from core.storage.r2_storage import create_r2_storage

r2 = create_r2_storage()

# Upload document
with open("case_document.pdf", "rb") as f:
    result = await r2.upload_file(
        file_content=f,
        filename="case_document.pdf",
        content_type="application/pdf",
        folder="cases/123",
        metadata={"case_id": "123", "document_type": "evidence"}
    )

print(f"Uploaded: {result['r2_key']}")
print(f"URL: {result['r2_url']}")

# Generate presigned URL (1 hour expiration)
presigned_url = await r2.generate_presigned_url(
    result['r2_key'],
    expiration=3600,
    force_download=True
)

# Download document
content = await r2.download_file(result['r2_key'])
```

---

## üîß –ú–∏–≥—Ä–∞—Ü–∏–∏ (Alembic)

### Setup Alembic

```bash
# Initialize Alembic
alembic init core/storage/migrations

# Edit alembic.ini to use env variable
# sqlalchemy.url = driver://user:pass@localhost/dbname  # pragma: allowlist secret
```

### –°–æ–∑–¥–∞—Ç—å –º–∏–≥—Ä–∞—Ü–∏—é

```bash
# Auto-generate migration
alembic revision --autogenerate -m "Add new column to cases table"

# Run migration
alembic upgrade head

# Rollback
alembic downgrade -1
```

---

## üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

```python
# tests/test_storage.py
import pytest
from core.storage.pinecone_store import create_pinecone_store
from core.llm.voyage_embedder import create_voyage_embedder

@pytest.mark.asyncio
async def test_pinecone_upsert_and_search():
    pinecone = create_pinecone_store(namespace="test")
    voyage = create_voyage_embedder()

    # Create test record
    record = MemoryRecord(
        user_id="test_user",
        text="test memory",
        type="fact"
    )

    # Generate embedding and upsert
    embedding = await voyage.aembed_documents([record.text])
    count = await pinecone.upsert([record], embedding)

    assert count == 1

    # Search
    query_emb = await voyage.aembed_query("test")
    results = await pinecone.search(query_emb, user_id="test_user")

    assert len(results) > 0
    assert results[0]['metadata']['text'] == "test memory"

    # Cleanup
    await pinecone.delete_all()
```

---

## üìä –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥

### PostgreSQL

```sql
-- Check connection pool
SELECT * FROM pg_stat_activity WHERE datname = 'megaagent';

-- Table sizes
SELECT
    schemaname,
    tablename,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename))
FROM pg_tables
WHERE schemaname = 'mega_agent'
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;

-- Slow queries
SELECT * FROM pg_stat_statements
WHERE query LIKE '%mega_agent%'
ORDER BY mean_exec_time DESC LIMIT 10;
```

### Pinecone

```python
# Get index stats
stats = await pinecone.get_stats()
print(f"Total vectors: {stats['total_vectors']}")
print(f"Dimension: {stats['dimension']}")
print(f"Namespaces: {stats['namespaces']}")
```

---

## üîí –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å

1. **Secrets Management**
   - ‚úÖ –í—Å–µ API –∫–ª—é—á–∏ –≤ `.env` (–Ω–µ –∫–æ–º–º–∏—Ç–∏—Ç—å!)
   - ‚úÖ –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ `SecretStr` –∏–∑ Pydantic
   - ‚ö†Ô∏è –í production: AWS Secrets Manager / HashiCorp Vault

2. **Database**
   - ‚úÖ SSL —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –≤ production
   - ‚úÖ –û–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–µ –ø—Ä–∞–≤–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –ë–î
   - ‚úÖ Regular backups

3. **R2**
   - ‚úÖ Presigned URLs –≤–º–µ—Å—Ç–æ public URLs
   - ‚úÖ CORS –Ω–∞—Å—Ç—Ä–æ–µ–Ω –ø—Ä–∞–≤–∏–ª—å–Ω–æ
   - ‚úÖ Lifecycle policies –¥–ª—è —Å—Ç–∞—Ä—ã—Ö —Ñ–∞–π–ª–æ–≤

---

## üöß –ß—Ç–æ –¥–∞–ª—å—à–µ (Phase 2)

–ü–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è Database Foundation:

1. **Redis Cache Layer**
   - Semantic caching –¥–ª—è LLM –∑–∞–ø—Ä–æ—Å–æ–≤
   - Session storage
   - Rate limiting

2. **Advanced Security**
   - Rate limiting middleware
   - Prompt injection detection
   - API key rotation

3. **Monitoring**
   - LangSmith integration
   - Prometheus metrics
   - Grafana dashboards

---

## ‚ùì Troubleshooting

### PostgreSQL connection failed
```bash
# Check if PostgreSQL is running
pg_isready -h localhost -p 5432

# Test connection
psql postgresql://user:password@localhost:5432/megaagent  # pragma: allowlist secret
```

### Pinecone "Index not found"
```python
# Pinecone index —Å–æ–∑–¥–∞–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏
# –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ API key –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π:
from core.storage.pinecone_store import create_pinecone_store
store = create_pinecone_store()
# Index will be created automatically
```

### R2 403 Forbidden
```bash
# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ R2 credentials
# Endpoint –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ:
# https://<account-id>.r2.cloudflarestorage.com
```

---

## üìû –ü–æ–¥–¥–µ—Ä–∂–∫–∞

- **Issues**: https://github.com/your-repo/issues
- **Documentation**: –°–º. —Ñ–∞–π–ª—ã –≤ `docs/`
- **API Reference**: –°–º. docstrings –≤ –∫–æ–¥–µ

---

**–°—Ç–∞—Ç—É—Å**: ‚úÖ Phase 1 Complete - Ready for Testing
**Next**: Phase 2 - Redis Cache & Security Hardening
