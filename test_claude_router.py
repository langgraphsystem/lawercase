#!/usr/bin/env python3
"""
–¢–µ—Å—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ Claude –≤ LLM Router
"""

import asyncio
from core.llm_router import create_llm_router, LLMRequest, ModelType

async def test_claude_availability():
    """–¢–µ—Å—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ Claude –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞"""
    print("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ Claude –≤ LLM Router...")

    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å –≤–∫–ª—é—á–µ–Ω–Ω—ã–º Claude
    config = {
        "providers": {
            "openai": {"enabled": True, "api_key": "demo-key"},
            "gemini": {"enabled": True, "api_key": "demo-key"},
            "claude": {"enabled": True, "api_key": "demo-key"},
            "mock": {"enabled": True, "failure_rate": 0.05}
        }
    }

    # –°–æ–∑–¥–∞–µ–º —Ä–æ—É—Ç–µ—Ä
    router = await create_llm_router(config)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–ø–∏—Å–æ–∫ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤
    print(f"\nüìã –ó–∞–≥—Ä—É–∂–µ–Ω–æ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤: {len(router.providers)}")
    for provider_type, provider in router.providers.items():
        print(f"   ‚úÖ {provider_type.value}: {provider.__class__.__name__}")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º health check –≤—Å–µ—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤
    print("\nüè• Health Check —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
    health_results = await router.health_check_all()
    for provider_name, is_healthy in health_results.items():
        status = "‚úÖ Healthy" if is_healthy else "‚ùå Unhealthy"
        print(f"   {provider_name}: {status}")

    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å —á–µ—Ä–µ–∑ Claude
    print("\nüß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Claude –∑–∞–ø—Ä–æ—Å–∞...")

    request = LLMRequest(
        messages=[{"role": "user", "content": "–ü—Ä–∏–≤–µ—Ç! –¢—ã Claude?"}],
        model_type=ModelType.CHAT,
        max_tokens=100,
        provider_preference=["claude"]  # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –≤—ã–±–∏—Ä–∞–µ–º Claude
    )

    response = await router.route_request(request)

    print(f"   –ü—Ä–æ–≤–∞–π–¥–µ—Ä: {response.provider}")
    print(f"   –ú–æ–¥–µ–ª—å: {response.model}")
    print(f"   –£—Å–ø–µ—Ö: {response.success}")
    print(f"   –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ: {response.content[:100]}...")
    print(f"   –¢–æ–∫–µ–Ω—ã: {response.tokens_used}")
    print(f"   –í—Ä–µ–º—è: {response.latency:.3f}s")

    # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤
    print("\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤:")
    stats = await router.get_providers_stats()
    for provider_name, provider_stats in stats.items():
        print(f"   {provider_name}:")
        print(f"     –î–æ—Å—Ç—É–ø–µ–Ω: {provider_stats.is_available}")
        print(f"     –ó–∞–ø—Ä–æ—Å–æ–≤: {provider_stats.total_requests}")
        print(f"     –£—Å–ø–µ—à–Ω—ã—Ö: {provider_stats.successful_requests}")
        print(f"     –°—Ä–µ–¥–Ω—è—è –∑–∞–¥–µ—Ä–∂–∫–∞: {provider_stats.average_latency:.3f}s")

if __name__ == "__main__":
    asyncio.run(test_claude_availability())